{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mitta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find any data file at c:\\Users\\mitta\\OneDrive - iiit-b\\Documents\\ML-Fiesta\\model\\https:\\onedrive.live.com\\?id=BA63D4A440C2FA9%21s1b49da28d90540b8a44655eb5d8b77fb&cid=0BA63D4A440C2FA9&redeem=aHR0cHM6Ly8xZHJ2Lm1zL2YvYy8wYmE2M2Q0YTQ0MGMyZmE5L0VpamFTUnNGMmJoQXBFWlY2MTJMZF9zQnZXV2c3RF9mMDE0ZWZSSDZFVFhjLUE%5FZT13QnNMVzk.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load your dataset\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Replace with the actual path to your dataset or use Hugging Face's datasets library\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://onedrive.live.com/?id=BA63D4A440C2FA9\u001b[39;49m\u001b[38;5;132;43;01m%21s\u001b[39;49;00m\u001b[38;5;124;43m1b49da28d90540b8a44655eb5d8b77fb&cid=0BA63D4A440C2FA9&redeem=aHR0cHM6Ly8xZHJ2Lm1zL2YvYy8wYmE2M2Q0YTQ0MGMyZmE5L0VpamFTUnNGMmJoQXBFWlY2MTJMZF9zQnZXV2c3RF9mMDE0ZWZSSDZFVFhjLUE\u001b[39;49m\u001b[38;5;132;43;01m%5F\u001b[39;49;00m\u001b[38;5;124;43mZT13QnNMVzk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Preprocess audio (resample, normalize, etc.)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_audio\u001b[39m(batch):\n",
      "File \u001b[1;32mc:\\Users\\mitta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:2132\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2127\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[0;32m   2128\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[0;32m   2129\u001b[0m )\n\u001b[0;32m   2131\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 2132\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2146\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2149\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   2150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[1;32mc:\\Users\\mitta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:1853\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[0;32m   1851\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[0;32m   1852\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[1;32m-> 1853\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[1;32mc:\\Users\\mitta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:1735\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1731\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1732\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a dataset script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or any data file in the same directory.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1733\u001b[0m     )\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1735\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any data file at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Couldn't find any data file at c:\\Users\\mitta\\OneDrive - iiit-b\\Documents\\ML-Fiesta\\model\\https:\\onedrive.live.com\\?id=BA63D4A440C2FA9%21s1b49da28d90540b8a44655eb5d8b77fb&cid=0BA63D4A440C2FA9&redeem=aHR0cHM6Ly8xZHJ2Lm1zL2YvYy8wYmE2M2Q0YTQ0MGMyZmE5L0VpamFTUnNGMmJoQXBFWlY2MTJMZF9zQnZXV2c3RF9mMDE0ZWZSSDZFVFhjLUE%5FZT13QnNMVzk."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torchaudio\n",
    "\n",
    "# Load your dataset\n",
    "# Replace with the actual path to your dataset or use Hugging Face's datasets library\n",
    "dataset = load_dataset(\"https://onedrive.live.com/?id=BA63D4A440C2FA9%21s1b49da28d90540b8a44655eb5d8b77fb&cid=0BA63D4A440C2FA9&redeem=aHR0cHM6Ly8xZHJ2Lm1zL2YvYy8wYmE2M2Q0YTQ0MGMyZmE5L0VpamFTUnNGMmJoQXBFWlY2MTJMZF9zQnZXV2c3RF9mMDE0ZWZSSDZFVFhjLUE%5FZT13QnNMVzk\")\n",
    "\n",
    "# Preprocess audio (resample, normalize, etc.)\n",
    "def preprocess_audio(batch):\n",
    "    audio = torchaudio.load(batch[\"audio_filepath\"])[0]  # Adjust based on dataset structure\n",
    "    batch[\"input_values\"] = processor(audio, sampling_rate=16000).input_values[0]\n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(preprocess_audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Trainer, TrainingArguments\n",
    "\n",
    "# Load pre-trained ASR model and processor\n",
    "model_name = \"facebook/wav2vec2-large-xlsr-53\"  # Example, use a model trained in regional languages if possible\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name)\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./asr_model\",\n",
    "    per_device_train_batch_size=16,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=3,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    logging_steps=100,\n",
    "    learning_rate=3e-4,\n",
    "    warmup_steps=500,\n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions.argmax(-1)\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    return {\"wer\": wer}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=processor,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"asr_kannada_model\")\n",
    "processor.save_pretrained(\"asr_kannada_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import torch\n",
    "\n",
    "# Load ASR model and processor\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"asr_kannada_model\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"asr_kannada_model\")\n",
    "\n",
    "# Function to transcribe audio file\n",
    "def transcribe_audio(audio_path):\n",
    "    audio, _ = torchaudio.load(audio_path)\n",
    "    inputs = processor(audio, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    return processor.decode(predicted_ids[0])\n",
    "\n",
    "# Transcribe all audio files in the corpus\n",
    "corpus_transcriptions = []\n",
    "for audio_path in corpus_audio_paths:  # Replace with your audio paths\n",
    "    transcript = transcribe_audio(audio_path)\n",
    "    corpus_transcriptions.append((audio_path, transcript))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load pre-trained BERT model for embeddings\n",
    "embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Embed corpus transcripts\n",
    "corpus_embeddings = embedder.encode([text for _, text in corpus_transcriptions], convert_to_tensor=True)\n",
    "\n",
    "# Function to answer a question\n",
    "def answer_question(question_audio):\n",
    "    # Transcribe question\n",
    "    question_text = transcribe_audio(question_audio)\n",
    "    \n",
    "    # Compute embedding for question\n",
    "    question_embedding = embedder.encode(question_text, convert_to_tensor=True)\n",
    "    \n",
    "    # Find closest matching audio in the corpus\n",
    "    similarities = util.pytorch_cos_sim(question_embedding, corpus_embeddings)\n",
    "    closest_idx = similarities.argmax()\n",
    "    \n",
    "    # Return the corresponding audio file and text\n",
    "    closest_audio_path, closest_text = corpus_transcriptions[closest_idx]\n",
    "    return closest_audio_path, closest_text\n",
    "\n",
    "# Example usage\n",
    "answer_audio_path, answer_text = answer_question(\"path/to/user_question_audio.wav\")\n",
    "print(f\"Answer found in audio: {answer_audio_path}\")\n",
    "print(\"Answer text:\", answer_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
